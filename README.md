
# ğŸ¤Ÿ AI-Powered Sign Language to Text and Speech Platform

## ğŸ“Œ Project Overview

This project converts **hand gestures** in **Sign Language** into **text** and **audible speech** in **real time**, enabling smoother communication between the hearing-impaired and others.

It leverages **computer vision**, **machine learning**, and **text-to-speech** technologies to recognize hand gestures, convert them into meaningful sentences, and then speak them aloud.

---

## ğŸ—ï¸ How the Project Was Built

The system was developed using a **step-by-step workflow** covering dataset creation, feature extraction, model training, and deployment.

### **1ï¸âƒ£ Dataset Creation**

* Created a **custom dataset** using `collectImgs.py`.
* **100 images per gesture** captured, ensuring varied angles & lighting.
* Dataset contains **38 classes**:

  * 26 alphabets (**Aâ€“Z**)
  * 10 digits (**0â€“9**)
  * 1 gesture for **Space**
  * 1 gesture for **Full Stop**

---

### **2ï¸âƒ£ Feature Extraction & Preprocessing**

* Used **MediaPipe** to extract **21 key hand landmarks** per image.
* Converted each into **normalized 2D coordinates (x, y)** â†’ 42 features per sample.
* Saved processed data as `.pkl` file using `createDataset.py`.

---

### **3ï¸âƒ£ Model Training**

* Implemented a **Random Forest Classifier** for high accuracy & fast training.
* Dataset split: **80% training**, **20% testing**.
* Achieved **high classification accuracy** with stable gesture recognition.

---

### **4ï¸âƒ£ Real-Time Inference & Conversion**

* Integrated trained model with `main.py` for live gesture detection.
* Added **stabilization buffer** to avoid misclassifications.
* Used **pyttsx3** for offline text-to-speech conversion.

---

### **5ï¸âƒ£ User Interface**

* **Tkinter-based GUI** for:

  * Live webcam feed display
  * Real-time gesture prediction
  * Sentence building & instant speech output

---

### **ğŸ”§ Technologies & Libraries Used**

* **Python** â€“ Core programming language
* **OpenCV** â€“ Image capture & processing
* **MediaPipe** â€“ Hand tracking & landmark detection
* **scikit-learn** â€“ Machine learning model
* **NumPy, Pandas** â€“ Data processing
* **pickle** â€“ Data/model serialization
* **pyttsx3** â€“ Text-to-speech
* **Tkinter** â€“ GUI development

---

## ğŸš€ Usage

### **Option 1 â€” Use the Pre-Trained Model**

Quick start with the provided **`model.p`** file:

1. **Clone the Repository**

   ```bash
   git clone https://github.com/your-username/sign-language-to-speech.git
   cd sign-language-to-speech
   ```
2. **Install Dependencies**

   ```bash
   pip install -r requirements.txt
   ```
3. **Run the Application**

   ```bash
   python main.py
   ```
4. **Requirements**

   * Functional **webcam**
   * **`model.p`** in same directory as `main.py`

---

### **Option 2 â€” Train Your Own Model**

#### 1ï¸âƒ£ **Collect a Custom Dataset**

```bash
python collectImgs.py
```

* Capture gesture images with your webcam.
* Adjust `number_of_classes` & `dataset_size` in the script as needed.

#### 2ï¸âƒ£ **Process the Dataset**

```bash
python createDataset.py
```

* Generates **`data.pickle`** with extracted features.

#### 3ï¸âƒ£ **Train the Model**

```bash
python trainClassifier.py
```

* Produces a new **`model.p`** for live detection.

---

## âœ¨ Project Features & Highlights

### ğŸ”¹ **Core Features**

* **Real-Time Gesture Recognition** â€“ Detects signs instantly from webcam feed.
* **Text-to-Speech Conversion** â€“ Speaks recognized signs for better communication.
* **Custom Dataset Support** â€“ Train with your own gesture set.
* **Multi-Class Detection** â€“ Recognizes **38 unique gestures** (Aâ€“Z, 0â€“9, Space, Full Stop).
* **Offline Functionality** â€“ Works without internet once trained.
* **User-Friendly GUI** â€“ Simple interface for smooth operation.

---

### ğŸŒŸ **Highlights**

* âœ… **AI-Powered Recognition** â€“ Combines **MediaPipe** & **Random Forest**.
* âœ… **Lightweight & Efficient** â€“ Works well on low-end systems.
* âœ… **Fully Customizable** â€“ Add/modify gestures easily.
* âœ… **Inclusive Communication** â€“ Bridges gap between hearing-impaired & others.

---

